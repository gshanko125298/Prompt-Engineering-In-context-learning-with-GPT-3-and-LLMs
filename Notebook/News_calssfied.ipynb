{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6baa3e",
   "metadata": {},
   "source": [
    "# Other Modeling using News dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89652247",
   "metadata": {},
   "outputs": [],
   "source": [
    "conh_api='mrCPBin4KFMnfaAsCrHueZtGGDhSxJcr6MxSRVrS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "sys.path.append('../scr')\n",
    "#import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Genet Shanko\\Prompt-Engineering-In-context-learning-with-GPT-3-and-LLMs\\Data\\Example_data.xlsx - Sheet1.csv\")\n",
    "data.head()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3334bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Additional Stopwords From nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "# Removing Stopwords And Remove Words With 2 Or Less Characters\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
    "            result.append(token)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f05c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying The Function To The Dataframe and Lower casing and removing punctuations\n",
    "# Lemmatization\n",
    "df['Body'] = df['Body'].astype(str).apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df['Body'] = df['Body'].astype(str).apply(preprocess)\n",
    "#data_df['clean'] =\" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(df) if w not in string.punctuation]))\n",
    "#Summary of title\n",
    "#lemmatization of Description \n",
    "df['Description'] = df['Description'].astype(str).apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df['Description'] = df['Description'].astype(str).apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to lemmatize words\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def lem(text):\n",
    "    return [lmtzr.lemmatize(word) for word in text]\n",
    "\n",
    "# Applying the function to each row of the text\n",
    "# i.e. reducing each word to its lemma\n",
    "tokens_des = df['Description'].apply(lem)\n",
    "tokens_body = df['Body'].apply(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df['Body'].apply(lambda x: len(x)) \n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df['Description'].apply(lambda x: len(x)) \n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank__to_10 = df['Analyst_Average_Score'].apply(lambda x: 'low' if x < 5 else 'high')\n",
    "df['rank_1'] = rank__to_10\n",
    "df['rank_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7435441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add low and high\n",
    "def handle_sub_class(value):\n",
    "    if value >= 0 and value < 1:\n",
    "        return \"low_1\"\n",
    "    elif value >= 1 and value < 2:\n",
    "        return \"low_2\"\n",
    "    elif value >= 2 and value < 3:\n",
    "        return \"low_3\"\n",
    "    elif value >= 3 and value < 4:\n",
    "        return \"low_4\"\n",
    "    elif value >= 4 and value < 5:\n",
    "        return \"low_5\"\n",
    "    elif value >= 5 and value < 6:\n",
    "        return \"high_1\"\n",
    "    elif value >= 6 and value < 7:\n",
    "        return \"high_2\"\n",
    "    elif value >= 7 and value < 8:\n",
    "        return \"high_3\"\n",
    "    elif value >= 8 and value < 9:\n",
    "        return \"high_4\"\n",
    "    else:\n",
    "        return \"high_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank the average\n",
    "df['rank_2'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(x))\n",
    "df['rank_3'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(int(\"{:.2f}\".format(x)[2])))\n",
    "df['rank_4'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(int(\"{:.2f}\".format(x)[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11569a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_score'] = df['rank_1'].map(str)+'__'+df['rank_2'].map(str)+'__'+df['rank_3'].map(str)+'__'+df['rank_4'].map(str)\n",
    "df['final_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df['Title'], df['final_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f543b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = y_train.unique().tolist()\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e551d5a",
   "metadata": {},
   "source": [
    "## Few-shot classification with the Classify endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f648bf9",
   "metadata": {},
   "source": [
    "###### Few-shot here means we just need to supply a few examples per class and have a decent classifier working. With Cohere’s Classify endpoint, the ‘training’ dataset is referred to as examples. The minimum number of examples per class is five, where each example consists of a text (in our case, the query), and a label (in our case, the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of examples per category\n",
    "#EX_PER_CAT = 6\n",
    "\n",
    "# Create list of examples containing texts and labels - sample from the dataset\n",
    "ex_texts, ex_labels = [], []\n",
    "for intent in intents:\n",
    "  ex_texts += X_train.tolist()\n",
    "  ex_labels += y_train.tolist()\n",
    "\n",
    "print(f'Number of classes: {len(intents)}')\n",
    "print(f'Total number of examples: {len(ex_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1498a2",
   "metadata": {},
   "source": [
    "###### Get classifications via the Classify endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate the examples via the Example module\n",
    "from cohere.classify import Example\n",
    "\n",
    "examples = list()\n",
    "for txt, lbl in zip(ex_texts,ex_labels):\n",
    "  examples.append(Example(txt,lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification\n",
    "def classify_text(text,examples):\n",
    "  classifications = co.classify(\n",
    "    model='medium', # model version - medium-22020720\n",
    "    inputs=[text],\n",
    "    examples=examples\n",
    "    )\n",
    "  return classifications.classifications[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset (this will take a few minutes)\n",
    "y_pred = X_test.apply(classify_text, args=(examples,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1d105",
   "metadata": {},
   "source": [
    "### Build your own classifier with the Embed endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd847ac9",
   "metadata": {},
   "source": [
    "##### In this section, we’ll look at how we can use the Embed endpoint to build a classifier. We are going to build a classification model using these embeddings as inputs. For this, we’ll use the Support Vector Machine (SVM) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92355b57",
   "metadata": {},
   "source": [
    "###### Generate embeddings for the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "def embed_text(text):\n",
    "  output = co.embed(\n",
    "                model='medium', # model version - medium-22020720\n",
    "                texts=text)\n",
    "  return output.embeddings\n",
    "\n",
    "# Embed and prepare the inputs\n",
    "X_train_emb = np.array(embed_text(X_train.tolist()))\n",
    "X_test_emb = np.array(embed_text(X_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb6373",
   "metadata": {},
   "source": [
    "###### Get classifications via the SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Prepare the labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_le = le.transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "\n",
    "# Initialize the model\n",
    "svm_classifier = SVC(class_weight='balanced')\n",
    "\n",
    "# Fit the training dataset to the model\n",
    "svm_classifier.fit(X_train_emb, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ddb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset\n",
    "y_pred_le = svm_classifier.predict(X_test_emb)\n",
    "y_pred_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd01fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test_le, y_pred_le)\n",
    "f1 = f1_score(y_test_le, y_pred_le, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698abbbd",
   "metadata": {},
   "source": [
    "##### Finetuning a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f268fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training dataset for finetuning\n",
    "df_train = pd.concat([X_train, y_train],axis=1)\n",
    "df_train.to_csv(\"../data/news_finetune.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788daa34",
   "metadata": {},
   "source": [
    "#### Create a finetuned model and Get classifications via the Classify endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf623b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification using the finetuned model\n",
    "def classify_text_finetune(text):\n",
    "  classifications = co.classify(\n",
    "    model='', # replace with your own finetune model ID \n",
    "    inputs=text\n",
    "    )\n",
    "  return classifications.classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff56861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset (this will take a few minutes)\n",
    "y_pred_raw = classify_text_finetune(X_test.tolist())\n",
    "y_pred = [y.prediction for y in y_pred_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a3d2e",
   "metadata": {},
   "source": [
    "##### it is percived that  how the different options compare performance-wise. And crucially, what’s important to note is the level of control that you have when working with the Classify endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab5b17",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdbe57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
