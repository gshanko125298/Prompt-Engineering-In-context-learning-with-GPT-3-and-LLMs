{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6baa3e",
   "metadata": {},
   "source": [
    "# Other Modeling using News dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89652247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5fdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "sys.path.append('../scr')\n",
    "#import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec37127f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Body</th>\n",
       "      <th>Link</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Analyst_Average_Score</th>\n",
       "      <th>Analyst_Rank</th>\n",
       "      <th>Reference_Final_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rassegnastampa.news</td>\n",
       "      <td>Boris Johnson using a taxpayer-funded jet for ...</td>\n",
       "      <td>…often trigger a protest vote that can upset…t...</td>\n",
       "      <td>Boris Johnson using a taxpayer-funded jet for ...</td>\n",
       "      <td>https://rassegnastampa.news/boris-johnson-usin...</td>\n",
       "      <td>2021-09-09T18:17:46.258006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>Stumbled across an interesting case, a woman f...</td>\n",
       "      <td>Stumbled across an interesting case, a woman f...</td>\n",
       "      <td>Stumbled across an interesting case, a woman f...</td>\n",
       "      <td>http://twitter.com/CoruscaKhaya/status/1435585...</td>\n",
       "      <td>2021-09-08T13:02:45.802298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atpe-tchad.info</td>\n",
       "      <td>Marché Résines dans les peintures et revêtemen...</td>\n",
       "      <td>…COVID-19…COVID…COVID…COVID-19 et Post COVID…C...</td>\n",
       "      <td>Le rapport d’étude de marché Résines dans les ...</td>\n",
       "      <td>http://atpe-tchad.info/2021/09/13/marche-resin...</td>\n",
       "      <td>2021-09-13T07:32:46.244403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badbluetech.bitnamiapp.com</td>\n",
       "      <td>AI drives data analytics surge, study finds</td>\n",
       "      <td>…hate raiders' linked to automated harassment ...</td>\n",
       "      <td>How to drive the funnel through content market...</td>\n",
       "      <td>http://badbluetech.bitnamiapp.com/p.php?sid=21...</td>\n",
       "      <td>2021-09-11T00:17:45.962605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kryptogazette.com</td>\n",
       "      <td>Triacetin Vertrieb Markt 2021: Globale Unterne...</td>\n",
       "      <td>…Abschnitten und Endanwendungen / Organisation...</td>\n",
       "      <td>Global Triacetin Vertrieb-Markt 2021 von Herst...</td>\n",
       "      <td>https://kryptogazette.com/2021/09/08/triacetin...</td>\n",
       "      <td>2021-09-08T12:47:46.078369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Domain  \\\n",
       "0         rassegnastampa.news   \n",
       "1                 twitter.com   \n",
       "2             atpe-tchad.info   \n",
       "3  badbluetech.bitnamiapp.com   \n",
       "4           kryptogazette.com   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Boris Johnson using a taxpayer-funded jet for ...   \n",
       "1  Stumbled across an interesting case, a woman f...   \n",
       "2  Marché Résines dans les peintures et revêtemen...   \n",
       "3        AI drives data analytics surge, study finds   \n",
       "4  Triacetin Vertrieb Markt 2021: Globale Unterne...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  …often trigger a protest vote that can upset…t...   \n",
       "1  Stumbled across an interesting case, a woman f...   \n",
       "2  …COVID-19…COVID…COVID…COVID-19 et Post COVID…C...   \n",
       "3  …hate raiders' linked to automated harassment ...   \n",
       "4  …Abschnitten und Endanwendungen / Organisation...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Boris Johnson using a taxpayer-funded jet for ...   \n",
       "1  Stumbled across an interesting case, a woman f...   \n",
       "2  Le rapport d’étude de marché Résines dans les ...   \n",
       "3  How to drive the funnel through content market...   \n",
       "4  Global Triacetin Vertrieb-Markt 2021 von Herst...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://rassegnastampa.news/boris-johnson-usin...   \n",
       "1  http://twitter.com/CoruscaKhaya/status/1435585...   \n",
       "2  http://atpe-tchad.info/2021/09/13/marche-resin...   \n",
       "3  http://badbluetech.bitnamiapp.com/p.php?sid=21...   \n",
       "4  https://kryptogazette.com/2021/09/08/triacetin...   \n",
       "\n",
       "                    timestamp  Analyst_Average_Score  Analyst_Rank  \\\n",
       "0  2021-09-09T18:17:46.258006                    0.0             4   \n",
       "1  2021-09-08T13:02:45.802298                    0.0             4   \n",
       "2  2021-09-13T07:32:46.244403                    0.0             4   \n",
       "3  2021-09-11T00:17:45.962605                    0.0             4   \n",
       "4  2021-09-08T12:47:46.078369                    0.0             4   \n",
       "\n",
       "   Reference_Final_Score  \n",
       "0                   1.96  \n",
       "1                  12.00  \n",
       "2                   0.05  \n",
       "3                   6.10  \n",
       "4                   0.13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Genet Shanko\\Prompt-Engineering-In-context-learning-with-GPT-3-and-LLMs\\Data\\Example_data.xlsx - Sheet1.csv\")\n",
    "data.head()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9336004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Domain                 10 non-null     object \n",
      " 1   Title                  10 non-null     object \n",
      " 2   Description            10 non-null     object \n",
      " 3   Body                   10 non-null     object \n",
      " 4   Link                   10 non-null     object \n",
      " 5   timestamp              10 non-null     object \n",
      " 6   Analyst_Average_Score  10 non-null     float64\n",
      " 7   Analyst_Rank           10 non-null     int64  \n",
      " 8   Reference_Final_Score  10 non-null     float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 848.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3334bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Additional Stopwords From nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b1fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "# Removing Stopwords And Remove Words With 2 Or Less Characters\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
    "            result.append(token)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f05c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying The Function To The Dataframe and Lower casing and removing punctuations\n",
    "# Lemmatization\n",
    "df['Body'] = df['Body'].astype(str).apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df['Body'] = df['Body'].astype(str).apply(preprocess)\n",
    "#data_df['clean'] =\" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(df) if w not in string.punctuation]))\n",
    "#Summary of title\n",
    "#lemmatization of Description \n",
    "df['Description'] = df['Description'].astype(str).apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df['Description'] = df['Description'].astype(str).apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to lemmatize words\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def lem(text):\n",
    "    return [lmtzr.lemmatize(word) for word in text]\n",
    "\n",
    "# Applying the function to each row of the text\n",
    "# i.e. reducing each word to its lemma\n",
    "tokens_des = df['Description'].apply(lem)\n",
    "tokens_body = df['Body'].apply(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df['Body'].apply(lambda x: len(x)) \n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df['Description'].apply(lambda x: len(x)) \n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank__to_10 = df['Analyst_Average_Score'].apply(lambda x: 'low' if x < 5 else 'high')\n",
    "df['rank_1'] = rank__to_10\n",
    "df['rank_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7435441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add low and high\n",
    "def handle_sub_class(value):\n",
    "    if value >= 0 and value < 1:\n",
    "        return \"low_1\"\n",
    "    elif value >= 1 and value < 2:\n",
    "        return \"low_2\"\n",
    "    elif value >= 2 and value < 3:\n",
    "        return \"low_3\"\n",
    "    elif value >= 3 and value < 4:\n",
    "        return \"low_4\"\n",
    "    elif value >= 4 and value < 5:\n",
    "        return \"low_5\"\n",
    "    elif value >= 5 and value < 6:\n",
    "        return \"high_1\"\n",
    "    elif value >= 6 and value < 7:\n",
    "        return \"high_2\"\n",
    "    elif value >= 7 and value < 8:\n",
    "        return \"high_3\"\n",
    "    elif value >= 8 and value < 9:\n",
    "        return \"high_4\"\n",
    "    else:\n",
    "        return \"high_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank the average\n",
    "df['rank_2'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(x))\n",
    "df['rank_3'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(int(\"{:.2f}\".format(x)[2])))\n",
    "df['rank_4'] = df['Analyst_Average_Score'].apply(lambda x: handle_sub_class(int(\"{:.2f}\".format(x)[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11569a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_score'] = df['rank_1'].map(str)+'__'+df['rank_2'].map(str)+'__'+df['rank_3'].map(str)+'__'+df['rank_4'].map(str)\n",
    "df['final_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df['Title'], df['final_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f543b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = y_train.unique().tolist()\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e551d5a",
   "metadata": {},
   "source": [
    "## Few-shot classification with the Classify endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f648bf9",
   "metadata": {},
   "source": [
    "###### Few-shot here means we just need to supply a few examples per class and have a decent classifier working. With Cohere’s Classify endpoint, the ‘training’ dataset is referred to as examples. The minimum number of examples per class is five, where each example consists of a text (in our case, the query), and a label (in our case, the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of examples per category\n",
    "#EX_PER_CAT = 6\n",
    "\n",
    "# Create list of examples containing texts and labels - sample from the dataset\n",
    "ex_texts, ex_labels = [], []\n",
    "for intent in intents:\n",
    "  ex_texts += X_train.tolist()\n",
    "  ex_labels += y_train.tolist()\n",
    "\n",
    "print(f'Number of classes: {len(intents)}')\n",
    "print(f'Total number of examples: {len(ex_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1498a2",
   "metadata": {},
   "source": [
    "###### Get classifications via the Classify endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate the examples via the Example module\n",
    "from cohere.classify import Example\n",
    "\n",
    "examples = list()\n",
    "for txt, lbl in zip(ex_texts,ex_labels):\n",
    "  examples.append(Example(txt,lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification\n",
    "def classify_text(text,examples):\n",
    "  classifications = co.classify(\n",
    "    model='medium', # model version - medium-22020720\n",
    "    inputs=[text],\n",
    "    examples=examples\n",
    "    )\n",
    "  return classifications.classifications[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset (this will take a few minutes)\n",
    "y_pred = X_test.apply(classify_text, args=(examples,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1d105",
   "metadata": {},
   "source": [
    "### Build your own classifier with the Embed endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd847ac9",
   "metadata": {},
   "source": [
    "##### In this section, we’ll look at how we can use the Embed endpoint to build a classifier. We are going to build a classification model using these embeddings as inputs. For this, we’ll use the Support Vector Machine (SVM) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92355b57",
   "metadata": {},
   "source": [
    "###### Generate embeddings for the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "def embed_text(text):\n",
    "  output = co.embed(\n",
    "                model='medium', # model version - medium-22020720\n",
    "                texts=text)\n",
    "  return output.embeddings\n",
    "\n",
    "# Embed and prepare the inputs\n",
    "X_train_emb = np.array(embed_text(X_train.tolist()))\n",
    "X_test_emb = np.array(embed_text(X_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb6373",
   "metadata": {},
   "source": [
    "###### Get classifications via the SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Prepare the labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_le = le.transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "\n",
    "# Initialize the model\n",
    "svm_classifier = SVC(class_weight='balanced')\n",
    "\n",
    "# Fit the training dataset to the model\n",
    "svm_classifier.fit(X_train_emb, y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ddb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset\n",
    "y_pred_le = svm_classifier.predict(X_test_emb)\n",
    "y_pred_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd01fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test_le, y_pred_le)\n",
    "f1 = f1_score(y_test_le, y_pred_le, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698abbbd",
   "metadata": {},
   "source": [
    "##### Finetuning a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f268fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training dataset for finetuning\n",
    "df_train = pd.concat([X_train, y_train],axis=1)\n",
    "df_train.to_csv(\"../data/news_finetune.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788daa34",
   "metadata": {},
   "source": [
    "#### Create a finetuned model and Get classifications via the Classify endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf623b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification using the finetuned model\n",
    "def classify_text_finetune(text):\n",
    "  classifications = co.classify(\n",
    "    model='', # replace with your own finetune model ID \n",
    "    inputs=text\n",
    "    )\n",
    "  return classifications.classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff56861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset (this will take a few minutes)\n",
    "y_pred_raw = classify_text_finetune(X_test.tolist())\n",
    "y_pred = [y.prediction for y in y_pred_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a3d2e",
   "metadata": {},
   "source": [
    "##### it is percived that  how the different options compare performance-wise. And crucially, what’s important to note is the level of control that you have when working with the Classify endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab5b17",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdbe57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
